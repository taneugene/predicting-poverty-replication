{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the CNN weights that were provided by the paper authors. These create a .npy file called `forward_feats.npy`, which should be placed in `setup_existing_model`.\n",
    "\n",
    "Run the script in `setup_existing_model` first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob as glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bunch of code from the Jean et al Github that is modified to work with Python3 and our data\n",
    "\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.linear_model as linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import EllipseCollection\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def predict_consumption(\n",
    "    X, y, k=5, k_inner=5, points=10,\n",
    "        alpha_low=1, alpha_high=5, margin=0.25):\n",
    "    \"\"\"\n",
    "    Plots predicted consumption\n",
    "    \"\"\"\n",
    "    y_hat, r2 = run_cv(X, y, k, k_inner, points, alpha_low, alpha_high)\n",
    "    return X, y, y_hat, r2\n",
    "\n",
    "\n",
    "def run_cv(X, y, k, k_inner, points, alpha_low, alpha_high, randomize=False):\n",
    "    \"\"\"\n",
    "    Runs nested cross-validation to make predictions and compute r-squared.\n",
    "    \"\"\"\n",
    "    alphas = np.logspace(alpha_low, alpha_high, points)\n",
    "    r2s = np.zeros((k,))\n",
    "    y_hat = np.zeros_like(y)\n",
    "    kf = KFold(n_splits=k, shuffle=True)\n",
    "    fold = 0\n",
    "    for train_idx, test_idx in kf.split(X):\n",
    "        r2s, y_hat, fold = evaluate_fold(\n",
    "            X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n",
    "            randomize)\n",
    "    return y_hat, r2s.mean()\n",
    "\n",
    "\n",
    "def scale_features(X_train, X_test):\n",
    "    \"\"\"\n",
    "    Scales features using StandardScaler.\n",
    "    \"\"\"\n",
    "    X_scaler = StandardScaler(with_mean=True, with_std=False)\n",
    "    X_train = X_scaler.fit_transform(X_train)\n",
    "    X_test = X_scaler.transform(X_test)\n",
    "    return X_train, X_test\n",
    "\n",
    "\n",
    "def train_and_predict_ridge(alpha, X_train, y_train, X_test):\n",
    "    \"\"\"\n",
    "    Trains ridge model and predicts test set.\n",
    "    \"\"\"\n",
    "    ridge = linear_model.Ridge(alpha)\n",
    "    ridge.fit(X_train, y_train)\n",
    "    y_hat = ridge.predict(X_test)\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def predict_inner_test_fold(X, y, y_hat, train_idx, test_idx, alpha):\n",
    "    \"\"\"\n",
    "    Predicts inner test fold.\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "    y_hat[test_idx] = train_and_predict_ridge(alpha, X_train, y_train, X_test)\n",
    "    return y_hat\n",
    "\n",
    "\n",
    "def find_best_alpha(X, y, k_inner, alphas):\n",
    "    \"\"\"\n",
    "    Finds the best alpha in an inner CV loop.\n",
    "    \"\"\"\n",
    "    kf = KFold(n_splits=k_inner, shuffle=True)\n",
    "    best_alpha = 0\n",
    "    best_r2 = 0\n",
    "    for idx, alpha in enumerate(alphas):\n",
    "        y_hat = np.zeros_like(y)\n",
    "        for train_idx, test_idx in kf.split(X):\n",
    "            y_hat = predict_inner_test_fold(\n",
    "                X, y, y_hat, train_idx, test_idx, alpha)\n",
    "        r2 = stats.pearsonr(y, y_hat)[0] ** 2\n",
    "        if r2 > best_r2:\n",
    "            best_alpha = alpha\n",
    "            best_r2 = r2\n",
    "    print('best alpha', best_alpha)\n",
    "    return best_alpha\n",
    "\n",
    "\n",
    "def evaluate_fold(\n",
    "    X, y, train_idx, test_idx, k_inner, alphas, r2s, y_hat, fold,\n",
    "        randomize):\n",
    "    \"\"\"\n",
    "    Evaluates one fold of outer CV.\n",
    "    \"\"\"\n",
    "    X_train, X_test = X[train_idx], X[test_idx]\n",
    "    y_train, y_test = y[train_idx], y[test_idx]\n",
    "    if randomize:\n",
    "        random.shuffle(y_train)\n",
    "    best_alpha = find_best_alpha(X_train, y_train, k_inner, alphas)\n",
    "    X_train, X_test = scale_features(X_train, X_test)\n",
    "    y_test_hat = train_and_predict_ridge(best_alpha, X_train, y_train, X_test)\n",
    "    r2 = stats.pearsonr(y_test, y_test_hat)[0] ** 2\n",
    "    r2s[fold] = r2\n",
    "    y_hat[test_idx] = y_test_hat\n",
    "    return r2s, y_hat, fold + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['setup_existing_model/nigeria_2013_forward_feats.npy',\n",
       " 'setup_existing_model/mw_2016_forward_feats.npy',\n",
       " 'setup_existing_model/tanzania_2011_forward_feats.npy',\n",
       " 'setup_existing_model/uganda_2011_forward_feats.npy']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lis_feats = glob.glob('setup_existing_model/*feats.npy')\n",
    "lis_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70677, 1)\n"
     ]
    }
   ],
   "source": [
    "fname = lis_feats[2]\n",
    "c = fname[fname.find('/')+1:fname.find('forward_feats.npy')-1]\n",
    "feats = np.load(fname)\n",
    "ims = os.listdir(\"process_data/data/ims_\"+c)\n",
    "# since we passed our images to the model in this order, we know index 0\n",
    "# of this dataframe corresponds to index 0 of feats\n",
    "df_im_raw = pd.DataFrame.from_dict({'images': ims}); df_im_raw.head()\n",
    "print(df_im_raw.shape)\n",
    "# this index corresponds to the row in \"forward_feats.npy\"\n",
    "df_im_raw['feat_index'] = np.arange(len(df_im_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_to_cons = pd.read_csv('process_data/data/output/{}_full_guide.csv'.format(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>nightlight_bin</th>\n",
       "      <th>images</th>\n",
       "      <th>check</th>\n",
       "      <th>clust_num</th>\n",
       "      <th>images_renamed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.866666</td>\n",
       "      <td>29.566666</td>\n",
       "      <td>-4.911112</td>\n",
       "      <td>29.611354</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>3.680708</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.866666_29.566665999999998.png</td>\n",
       "      <td>True</td>\n",
       "      <td>989</td>\n",
       "      <td>-4.866666_29.566665999999998_989.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.875000</td>\n",
       "      <td>29.566666</td>\n",
       "      <td>-4.911112</td>\n",
       "      <td>29.611354</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>3.680708</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.875_29.566665999999998.png</td>\n",
       "      <td>True</td>\n",
       "      <td>989</td>\n",
       "      <td>-4.875_29.566665999999998_989.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.883333</td>\n",
       "      <td>29.566666</td>\n",
       "      <td>-4.911112</td>\n",
       "      <td>29.611354</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>3.680708</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.883333_29.566665999999998.png</td>\n",
       "      <td>True</td>\n",
       "      <td>989</td>\n",
       "      <td>-4.883333_29.566665999999998_989.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.891666</td>\n",
       "      <td>29.566666</td>\n",
       "      <td>-4.911112</td>\n",
       "      <td>29.611354</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>3.680708</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.891666000000001_29.566665999999998.png</td>\n",
       "      <td>True</td>\n",
       "      <td>989</td>\n",
       "      <td>-4.891666000000001_29.566665999999998_989.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.900000</td>\n",
       "      <td>29.566666</td>\n",
       "      <td>-4.911112</td>\n",
       "      <td>29.611354</td>\n",
       "      <td>9.266667</td>\n",
       "      <td>3.680708</td>\n",
       "      <td>2</td>\n",
       "      <td>-4.9_29.566665999999998.png</td>\n",
       "      <td>True</td>\n",
       "      <td>989</td>\n",
       "      <td>-4.9_29.566665999999998_989.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0 -4.866666  29.566666  -4.911112  29.611354    9.266667     3.680708   \n",
       "1 -4.875000  29.566666  -4.911112  29.611354    9.266667     3.680708   \n",
       "2 -4.883333  29.566666  -4.911112  29.611354    9.266667     3.680708   \n",
       "3 -4.891666  29.566666  -4.911112  29.611354    9.266667     3.680708   \n",
       "4 -4.900000  29.566666  -4.911112  29.611354    9.266667     3.680708   \n",
       "\n",
       "   nightlight_bin                                     images  check  \\\n",
       "0               2           -4.866666_29.566665999999998.png   True   \n",
       "1               2              -4.875_29.566665999999998.png   True   \n",
       "2               2           -4.883333_29.566665999999998.png   True   \n",
       "3               2  -4.891666000000001_29.566665999999998.png   True   \n",
       "4               2                -4.9_29.566665999999998.png   True   \n",
       "\n",
       "   clust_num                                 images_renamed  \n",
       "0        989           -4.866666_29.566665999999998_989.png  \n",
       "1        989              -4.875_29.566665999999998_989.png  \n",
       "2        989           -4.883333_29.566665999999998_989.png  \n",
       "3        989  -4.891666000000001_29.566665999999998_989.png  \n",
       "4        989                -4.9_29.566665999999998_989.png  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# notice we have duplicate images that we only pass once to the model to reduce runtime load\n",
    "# we need to add a column that tells us what index of feats to look at for that image\n",
    "im_to_cons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112885, 11)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_cons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we can merge\n",
    "im_to_cons = pd.merge(left=im_to_cons, right=df_im_raw, on='images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112885, 12)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_to_cons.shape # we shouldn't lose any rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = im_to_cons.groupby(['clust_lat', 'clust_lon'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1520"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_clusts = len(group); num_clusts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((num_clusts, 4096))\n",
    "y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this goes through each cluster group and finds all images that are in the cluster\n",
    "# it aggregates the features for those images across the cluster\n",
    "for i, g in enumerate(group):\n",
    "    lat, long = g[0]\n",
    "    im_sub = im_to_cons[(im_to_cons['clust_lat'] == lat) & (im_to_cons['clust_lon'] == long)].reset_index(drop=True)\n",
    "    agg_feats = np.zeros((len(im_sub), 4096))\n",
    "    for j, d in im_sub.iterrows():\n",
    "        agg_feats[j,:] = feats[d.feat_index]\n",
    "    agg_feats = agg_feats.mean(axis=0) # averages the features across all images in the cluster\n",
    "    \n",
    "    x[i,:] = agg_feats\n",
    "    y.append(g[1]['consumption'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "y_log = np.log(y) # try predicting consumption and log consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1520, 4096)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha 10.0\n",
      "best alpha 10.0\n",
      "best alpha 10.0\n",
      "best alpha 1668.100537200059\n",
      "best alpha 100000.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0064997318728015575"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, r2 = predict_consumption(x, y_log)\n",
    "r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha 1668.100537200059\n",
      "best alpha 27.825594022071243\n",
      "best alpha 100000.0\n",
      "best alpha 27.825594022071243\n",
      "best alpha 77.4263682681127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.007776706039778575"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _, _, r2 = predict_consumption(x, y)\n",
    "r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<strong> Important Note </strong> <br>\n",
    "If you read the original paper, you'll see that the paper's consumption prediction has r^2 of 0.33 or higher. Why is ours so much lower using their weights? Well, here we are using (free) 2019 images to predict their 2016 consumption values. Ideally, we should download 2016 images, and if we want to follow the paper exactly, we download 2013 images (for Malawi at least). However, this doesn't explain why if I train the model from scratch, it matches the paper's performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
