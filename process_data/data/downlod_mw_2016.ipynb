{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to download \"2016\" (really 2018-2019 but using the images determined by the script that was run on the 2016 data) Malawi images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output/LSMS/malawi_2016/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locs = sorted(glob.glob('output/LSMS/*/candidate_download_locs.txt'))\n",
    "locs\n",
    "foldernames = [loc[12:loc.find('/',12)] for loc in locs]\n",
    "fls = list(zip(foldernames,locs))\n",
    "fls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each country in this folder should have:\n",
    "1. 'nightlights.npy'\n",
    "2. 'consumptions.npy'\n",
    "These are aggregated at a cluster level.\n",
    "\n",
    "This function will add in these values at the cluster level for each image. That is, we now get a dataframe that has cluster nightlight and consumption values for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(country, df_orig):\n",
    "    c_nightlight = np.load('output/LSMS/{}/nightlights.npy'.format(country))\n",
    "    c_consumption = np.load('output/LSMS/{}/consumptions.npy'.format(country))\n",
    "    c_groups = df_orig.groupby(['clust_lat', 'clust_lon'])\n",
    "    counts = c_groups.count()\n",
    "    counts['nightlight'] = c_nightlight\n",
    "    counts['consumption'] = c_consumption\n",
    "    counts = counts.reset_index().drop(['im_lat', 'im_lon'], axis=1)\n",
    "    df_c = pd.merge(left=df_orig, right=counts, on=['clust_lat', 'clust_lon'])\n",
    "    return df_c\n",
    "dfs = [create_df(f,pd.read_csv(l, sep=' ', header=None, \n",
    "                               names=['im_lat', 'im_lon', 'clust_lat', 'clust_lon'])) for (f,l) in fls]\n",
    "[df.shape for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most nightlights are 0\n",
    "# let's download images that have nonzero nightlights to induce variety into the model\n",
    "for df in dfs:\n",
    "    print((df['nightlight'] == 0).mean())\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 10% of 0 nightlight images until  the percentages are less than 10\n",
    "def drop_0s(df, frac=0.1):\n",
    "    i = 1\n",
    "    while (df['nightlight'].values==0).mean() > .1:\n",
    "        i += 1\n",
    "#         print(i)\n",
    "        z_inds = np.argwhere(df['nightlight'].values == 0).reshape(-1)\n",
    "        drop = np.random.choice(z_inds, int(frac*len(z_inds))).reshape(-1)\n",
    "        df = df.drop(df.index[drop])\n",
    "    return df\n",
    "dfs = [drop_0s(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(df['nightlight'] < 1).mean() for df in dfs] # still most data is under 1 and small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference this made was only a few images so i didn't do this, quite arbitrary since the number of gridcells with\n",
    "# nightlights below 1 in non-Malawi is quite low anyway.\n",
    "def drop_under(df, cutoff=1, frac=0.1):\n",
    "    z_inds = np.argwhere(df['nightlight'].values <= cutoff).reshape(-1)\n",
    "    drop = np.random.choice(z_inds, int(frac*len(z_inds))).reshape(-1)\n",
    "    df = df.drop(df.index[drop])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[4]\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "X = df['nightlight'].values.reshape(-1,1)\n",
    "gmm = GMM(n_components=3).fit(X)\n",
    "labels = gmm.predict(df['nightlight'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(labels==0).mean(), (labels==1).mean(), (labels==2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['nightlight'][labels==0].max(), df['nightlight'][labels==1].max(), df['nightlight'][labels==2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's smudge these numbers a little to raise the percentage in class 2\n",
    "# we need the distribution to be somewhat even\n",
    "# Mather did this for all, cutoffs seem to work pretty well for all countries.\n",
    "(df['nightlight'] < 1.5).mean(), \\\n",
    "((df['nightlight'] >= 1.5) & (df['nightlight'] < 11)).mean(), \\\n",
    "(df['nightlight'] >= 11).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for df in dfs:\n",
    "    df['nightlight_bin'] = (df['nightlight'] < 1.5)*1 + \\\n",
    "                    ((df['nightlight'] >= 1.5) & (df['nightlight'] < 11))*2 + \\\n",
    "                    (df['nightlight'] >= 11)*3\n",
    "    d.append(df)\n",
    "dfs = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs)):\n",
    "    dfs[i].to_csv('output/{}_guide.csv'.format(fls[i][0]), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we don't need to download repeat images, as that reduces our download size significantly\n",
    "# some images can belong to 2+ clusters\n",
    "print(df.drop_duplicates(['im_lat', 'im_lon']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_download = [df.drop_duplicates(['im_lat', 'im_lon']) for df in dfs]\n",
    "for i in range(len(ll_download)):\n",
    "    ll_download[i].to_csv('output/{}_download.csv'.format(fls[i][0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>im_lat</th>\n",
       "      <th>im_lon</th>\n",
       "      <th>clust_lat</th>\n",
       "      <th>clust_lon</th>\n",
       "      <th>nightlight</th>\n",
       "      <th>consumption</th>\n",
       "      <th>nightlight_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.616667</td>\n",
       "      <td>2.924999</td>\n",
       "      <td>8.654959</td>\n",
       "      <td>2.969085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.036260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.675000</td>\n",
       "      <td>2.933333</td>\n",
       "      <td>8.654959</td>\n",
       "      <td>2.969085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.036260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.666667</td>\n",
       "      <td>2.941666</td>\n",
       "      <td>8.654959</td>\n",
       "      <td>2.969085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.036260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.650000</td>\n",
       "      <td>2.941666</td>\n",
       "      <td>8.654959</td>\n",
       "      <td>2.969085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.036260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.633334</td>\n",
       "      <td>2.941666</td>\n",
       "      <td>8.654959</td>\n",
       "      <td>2.969085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.036260</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16898</th>\n",
       "      <td>13.058334</td>\n",
       "      <td>13.833333</td>\n",
       "      <td>13.093234</td>\n",
       "      <td>13.814570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.792612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16899</th>\n",
       "      <td>13.083334</td>\n",
       "      <td>13.841666</td>\n",
       "      <td>13.093234</td>\n",
       "      <td>13.814570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.792612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16900</th>\n",
       "      <td>13.141667</td>\n",
       "      <td>13.849999</td>\n",
       "      <td>13.093234</td>\n",
       "      <td>13.814570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.792612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16901</th>\n",
       "      <td>13.108334</td>\n",
       "      <td>13.849999</td>\n",
       "      <td>13.093234</td>\n",
       "      <td>13.814570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.792612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16902</th>\n",
       "      <td>13.066667</td>\n",
       "      <td>13.849999</td>\n",
       "      <td>13.093234</td>\n",
       "      <td>13.814570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.792612</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16903 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          im_lat     im_lon  clust_lat  clust_lon  nightlight  consumption  \\\n",
       "0       8.616667   2.924999   8.654959   2.969085         0.0     2.036260   \n",
       "1       8.675000   2.933333   8.654959   2.969085         0.0     2.036260   \n",
       "2       8.666667   2.941666   8.654959   2.969085         0.0     2.036260   \n",
       "3       8.650000   2.941666   8.654959   2.969085         0.0     2.036260   \n",
       "4       8.633334   2.941666   8.654959   2.969085         0.0     2.036260   \n",
       "...          ...        ...        ...        ...         ...          ...   \n",
       "16898  13.058334  13.833333  13.093234  13.814570         0.0     2.792612   \n",
       "16899  13.083334  13.841666  13.093234  13.814570         0.0     2.792612   \n",
       "16900  13.141667  13.849999  13.093234  13.814570         0.0     2.792612   \n",
       "16901  13.108334  13.849999  13.093234  13.814570         0.0     2.792612   \n",
       "16902  13.066667  13.849999  13.093234  13.814570         0.0     2.792612   \n",
       "\n",
       "       nightlight_bin  \n",
       "0                   1  \n",
       "1                   1  \n",
       "2                   1  \n",
       "3                   1  \n",
       "4                   1  \n",
       "...               ...  \n",
       "16898               1  \n",
       "16899               1  \n",
       "16900               1  \n",
       "16901               1  \n",
       "16902               1  \n",
       "\n",
       "[16903 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if the script fails halfway through, you can read this and see what is already downloaded\n",
    "# remove the images already downloaded from this dataframe and then continue downloading\n",
    "\n",
    "############## THIS DOENS'T WORK AND NOT SURE WHY IT IS MISCOUNTING\n",
    "# run = 'nigeria_2013'\n",
    "# download = pd.read_csv('output/{}_download.csv'.format(run))\n",
    "# downloaded = os.listdir('ims_{}/'.format(run))\n",
    "# lats = []\n",
    "# longs = []\n",
    "# for im in downloaded:\n",
    "# #     print(im)\n",
    "#     im = im[:-4].split('_')\n",
    "#     lats.append(float(im[0]))\n",
    "#     longs.append(float(im[1]))\n",
    "\n",
    "# downloaded = pd.DataFrame.from_dict({'im_lat': lats, 'im_lon': longs})\n",
    "\n",
    "# a = download.set_index(['im_lat', 'im_lon']).index\n",
    "# b = downloaded.set_index(['im_lat', 'im_lon']).index\n",
    "\n",
    "# mask = ~a.isin(b)\n",
    "# download = download.loc[mask].reset_index(drop=True)\n",
    "# df = download; c = run\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Images\n",
    "\n",
    "Now we actually download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Interface for downloading aerial imagery from Google Static Maps API.\n",
    "- Get an API key at https://developers.google.com/maps/documentation/maps-static/intro\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "class ImageryDownloader:\n",
    "    def __init__(self, access_token):\n",
    "        \"\"\"Initializes the object with an access token\"\"\"\n",
    "        self.access_token = access_token\n",
    "        self.url = 'https://maps.googleapis.com/maps/api/staticmap?center={},{}&zoom={}&size=400x400&maptype=satellite&key={}'\n",
    "    \n",
    "    def download(self, lat, long, zoom):\n",
    "        \"\"\"Downloads lat long\n",
    "        \"\"\"\n",
    "        res = requests.get(self.url.format(lat, long, zoom, self.access_token))\n",
    "        image = Image.open(BytesIO(res.content))\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = None\n",
    "with open('api_key.txt', 'r') as f:\n",
    "    access = f.readlines()[0]\n",
    "    \n",
    "im_downloader = ImageryDownloader(access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,l in fls:\n",
    "    os.makedirs('ims_{}'.format(f), exist_ok=True)\n",
    "#  Change selection to download\n",
    "selection =4\n",
    "c = fls[selection][0]\n",
    "df = ll_download[selection]\n",
    "[df.shape for df in dfs],[ll.shape for ll in ll_download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nigeria_2013\n",
      "gathering images for im_lats and im_lons in this selection\n",
      "0, 100, 200, 300, 400, 500, 600, 700, 800, 900, 1000, 1100, 1200, 1300, 1400, 1500, 1600, 1700, "
     ]
    }
   ],
   "source": [
    "print(c)\n",
    "print('gathering images for im_lats and im_lons in this selection')\n",
    "\n",
    "if True:\n",
    "    im_names = []\n",
    "    zoom = 16\n",
    "    for i, r in df.iterrows():\n",
    "        lat = r.im_lat\n",
    "        long = r.im_lon\n",
    "        try:\n",
    "            im = im_downloader.download(lat, long, zoom)\n",
    "            name = str(lat) + '_' + str(long)\n",
    "            im.save('ims_{}/{}.png'.format(f,name))\n",
    "            im_names.append(name + '.png')\n",
    "        except:\n",
    "            im_names.append(np.nan)\n",
    "        if i % 100 == 0:\n",
    "            # the counting is off because the indices from mw_download aren't continuous because we modified the dataframe\n",
    "            print(i, end=', ')\n",
    "\n",
    "    df['images'] = im_names\n",
    "#     df.to_csv('output/{}_download_info.csv'.format(c), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotorch",
   "language": "python",
   "name": "geotorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
