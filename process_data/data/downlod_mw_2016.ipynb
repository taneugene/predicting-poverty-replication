{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Script to download \"2016\" (really 2018-2019 but using the images determined by the script that was run on the 2016 data) Malawi images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "download = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidate_download_locs.txt  consumptions.npy  households.npy  lons.npy\r\n",
      "cluster.csv\t\t     household.csv     lats.npy        nightlights.npy\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/LSMS/malawi_2016/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('malawi-2016', 'output/LSMS/malawi-2016/candidate_download_locs.txt'),\n",
       " ('malawi_2016', 'output/LSMS/malawi_2016/candidate_download_locs.txt'),\n",
       " ('nigeria_2013', 'output/LSMS/nigeria_2013/candidate_download_locs.txt'),\n",
       " ('tanzania_2011', 'output/LSMS/tanzania_2011/candidate_download_locs.txt'),\n",
       " ('uganda_2011', 'output/LSMS/uganda_2011/candidate_download_locs.txt')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "locs = sorted(glob.glob('output/LSMS/*/candidate_download_locs.txt'))\n",
    "locs\n",
    "foldernames = [loc[12:loc.find('/',12)] for loc in locs]\n",
    "fls = list(zip(foldernames,locs))\n",
    "fls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each country in this folder should have:\n",
    "1. 'nightlights.npy'\n",
    "2. 'consumptions.npy'\n",
    "These are aggregated at a cluster level.\n",
    "\n",
    "This function will add in these values at the cluster level for each image. That is, we now get a dataframe that has cluster nightlight and consumption values for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(90943, 6), (90943, 6), (67227, 6), (177931, 6), (74033, 6)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_df(country, df_orig):\n",
    "    c_nightlight = np.load('output/LSMS/{}/nightlights.npy'.format(country))\n",
    "    c_consumption = np.load('output/LSMS/{}/consumptions.npy'.format(country))\n",
    "    c_groups = df_orig.groupby(['clust_lat', 'clust_lon'])\n",
    "    counts = c_groups.count()\n",
    "    counts['nightlight'] = c_nightlight\n",
    "    counts['consumption'] = c_consumption\n",
    "    counts = counts.reset_index().drop(['im_lat', 'im_lon'], axis=1)\n",
    "    df_c = pd.merge(left=df_orig, right=counts, on=['clust_lat', 'clust_lon'])\n",
    "    return df_c\n",
    "dfs = [create_df(f,pd.read_csv(l, sep=' ', header=None, \n",
    "                               names=['im_lat', 'im_lon', 'clust_lat', 'clust_lon'])) for (f,l) in fls]\n",
    "[df.shape for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4980042444168325\n",
      "(90943, 6)\n",
      "0.5004673256875185\n",
      "(90943, 6)\n",
      "0.2560132089785354\n",
      "(67227, 6)\n",
      "0.4047861249585514\n",
      "(177931, 6)\n",
      "0.5856982696905434\n",
      "(74033, 6)\n"
     ]
    }
   ],
   "source": [
    "# most nightlights are 0\n",
    "# let's download images that have nonzero nightlights to induce variety into the model\n",
    "for df in dfs:\n",
    "    print((df['nightlight'] == 0).mean())\n",
    "    print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop 10% of 0 nightlight images until  the percentages are less than 10\n",
    "def drop_0s(df, frac=0.1):\n",
    "    i = 1\n",
    "    while (df['nightlight'].values==0).mean() > .1:\n",
    "        i += 1\n",
    "#         print(i)\n",
    "        z_inds = np.argwhere(df['nightlight'].values == 0).reshape(-1)\n",
    "        drop = np.random.choice(z_inds, int(frac*len(z_inds))).reshape(-1)\n",
    "        df = df.drop(df.index[drop])\n",
    "    return df\n",
    "dfs = [drop_0s(df) for df in dfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5017355632691701,\n",
       " 0.49796,\n",
       " 0.30389652736264333,\n",
       " 0.3215225459189358,\n",
       " 0.35740850059031876]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(df['nightlight'] < 1).mean() for df in dfs] # still most data is under 1 and small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The difference this made was only a few images so i didn't do this, quite arbitrary since the number of gridcells with\n",
    "# nightlights below 1 in non-Malawi is quite low anyway.\n",
    "def drop_under(df, cutoff=1, frac=0.1):\n",
    "    z_inds = np.argwhere(df['nightlight'].values <= cutoff).reshape(-1)\n",
    "    drop = np.random.choice(z_inds, int(frac*len(z_inds))).reshape(-1)\n",
    "    df = df.drop(df.index[drop])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[4]\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "X = df['nightlight'].values.reshape(-1,1)\n",
    "gmm = GMM(n_components=3).fit(X)\n",
    "labels = gmm.predict(df['nightlight'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2641086186540732, 0.6264167650531287, 0.10947461629279812)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(labels==0).mean(), (labels==1).mean(), (labels==2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59.30578512396694, 4.340909090909091, 25.380165289256198)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nightlight'][labels==0].max(), df['nightlight'][labels==1].max(), df['nightlight'][labels==2].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.41685360094451, 0.28202479338842973, 0.3011216056670602)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's smudge these numbers a little to raise the percentage in class 2\n",
    "# we need the distribution to be somewhat even\n",
    "# Mather did this for all, cutoffs seem to work pretty well for all countries.\n",
    "(df['nightlight'] < 1.5).mean(), \\\n",
    "((df['nightlight'] >= 1.5) & (df['nightlight'] < 11)).mean(), \\\n",
    "(df['nightlight'] >= 11).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for df in dfs:\n",
    "    df['nightlight_bin'] = (df['nightlight'] < 1.5)*1 + \\\n",
    "                    ((df['nightlight'] >= 1.5) & (df['nightlight'] < 11))*2 + \\\n",
    "                    (df['nightlight'] >= 11)*3\n",
    "    d.append(df)\n",
    "dfs = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dfs)):\n",
    "    dfs[i].to_csv('output/{}_guide.csv'.format(fls[i][0]), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25246, 7)\n"
     ]
    }
   ],
   "source": [
    "# we don't need to download repeat images, as that reduces our download size significantly\n",
    "# some images can belong to 2+ clusters\n",
    "print(df.drop_duplicates(['im_lat', 'im_lon']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_download = [df.drop_duplicates(['im_lat', 'im_lon']) for df in dfs]\n",
    "for i in range(len(ll_download)):\n",
    "    ll_download[i].to_csv('output/{}_download.csv'.format(fls[i][0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the script fails halfway through, you can read this and see what is already downloaded\n",
    "# remove the images already downloaded from this dataframe and then continue downloading\n",
    "\n",
    "# mw_download = pd.read_csv('mw_2016_download.csv')\n",
    "# downloaded = os.listdir('ims_malawi_2016/')\n",
    "# lats = []\n",
    "# longs = []\n",
    "# for im in downloaded:\n",
    "#     im = im[:-4].split('_')\n",
    "#     lats.append(float(im[0]))\n",
    "#     longs.append(float(im[1]))\n",
    "\n",
    "# downloaded = pd.DataFrame.from_dict({'im_lat': lats, 'im_lon': longs})\n",
    "\n",
    "# a = mw_download.set_index(['im_lat', 'im_lon']).index\n",
    "# b = downloaded.set_index(['im_lat', 'im_lon']).index\n",
    "\n",
    "# mask = ~a.isin(b)\n",
    "# mw_download = mw_download.loc[mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Images\n",
    "\n",
    "Now we actually download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Interface for downloading aerial imagery from Google Static Maps API.\n",
    "- Get an API key at https://developers.google.com/maps/documentation/maps-static/intro\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "class ImageryDownloader:\n",
    "    def __init__(self, access_token):\n",
    "        \"\"\"Initializes the object with an access token\"\"\"\n",
    "        self.access_token = access_token\n",
    "        self.url = 'https://maps.googleapis.com/maps/api/staticmap?center={},{}&zoom={}&size=400x400&maptype=satellite&key={}'\n",
    "    \n",
    "    def download(self, lat, long, zoom):\n",
    "        \"\"\"Downloads lat long\n",
    "        \"\"\"\n",
    "        res = requests.get(self.url.format(lat, long, zoom, self.access_token))\n",
    "        image = Image.open(BytesIO(res.content))\n",
    "\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "access = None\n",
    "with open('api_key.txt', 'r') as f:\n",
    "    access = f.readlines()[0]\n",
    "    \n",
    "im_downloader = ImageryDownloader(access)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(50704, 7), (50000, 7), (55203, 7), (116673, 7), (33880, 7)],\n",
       " [(28179, 7), (33580, 7), (46423, 7), (70772, 7), (25246, 7)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for f,l in fls:\n",
    "    os.makedirs('ims_{}'.format(f), exist_ok=True)\n",
    "[df.shape for df in dfs],[ll.shape for ll in ll_download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uganda_2011\n",
      "gathering images for im_lats and im_lons in this selection\n",
      "100, "
     ]
    }
   ],
   "source": [
    "# Change selection to download\n",
    "selection =4\n",
    "f = fls[selection][0]\n",
    "df = ll_download[selection]\n",
    "print(f)\n",
    "print('gathering images for im_lats and im_lons in this selection')\n",
    "download = True\n",
    "if download:\n",
    "    im_names = []\n",
    "    zoom = 16\n",
    "    for i, r in df.iterrows():\n",
    "        lat = r.im_lat\n",
    "        long = r.im_lon\n",
    "        try:\n",
    "            im = im_downloader.download(lat, long, zoom)\n",
    "            name = str(lat) + '_' + str(long)\n",
    "            im.save('ims_{}/{}.png'.format(f,name))\n",
    "            im_names.append(name + '.png')\n",
    "        except:\n",
    "            im_names.append(np.nan)\n",
    "        if i % 100 == 0:\n",
    "            # the counting is off because the indices from mw_download aren't continuous because we modified the dataframe\n",
    "            print(i, end=', ')\n",
    "\n",
    "    df['images'] = im_names\n",
    "    df.to_csv('output/{}_download_info.csv'.format(f), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geotorch",
   "language": "python",
   "name": "geotorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
